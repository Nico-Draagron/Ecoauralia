# ðŸŒ¿ EcoAuralia: Acoustic Animal Recognition with AI

## ðŸ“˜ Introduction  
**EcoAuralia** is a lightweight command-line AI tool, developed as the first graded assignment for the IA 1 course. It â€œlistensâ€ to short `.ogg` audio clips of farm animals and:

- **Classifies** them as **dog**, **cat**, **cow**, **pig** or **sheep**  
- **Generates** a detailed natural-language description via Googleâ€™s Gemini API  
- **Launches** a real-world image search in your browser  

Under the hood it uses two complementary approaches:
1. **Spectrogram + MobileNetV2**: converts 5 s audio into 128Ã—128 Mel-spectrograms and fine-tunes a pretrained MobileNetV2 head.  
2. **MFCC + Custom CNN**: extracts 13 MFCCs (padded/cropped to 13Ã—216) and feeds them to a small 2-layer convolutional network.

---

## ðŸ§° Dependencies

| Library               | Purpose                                                |
|-----------------------|--------------------------------------------------------|
| TensorFlow / Keras    | Model definition & training (CNNs)                     |
| Librosa               | Audio I/O & feature extraction (spectrograms, MFCCs)   |
| NumPy                 | Numerical array operations                             |
| Matplotlib            | Rendering & saving spectrogram images                  |
| google-generativeai   | Text description generation (Gemini)                   |
| webbrowser            | Opening Google image search in the default browser     |
| (Optional) diffusers  | Local image synthesis via Hugging Face (disabled now)  |

Install with:
\`\`\`bash
pip install tensorflow librosa matplotlib numpy google-generativeai
\`\`\`

---

## ðŸ”§ Project Structure

\`\`\`
ecoauralia/
â”œâ”€â”€ classificador.py               # Spectrogram classification + Gemini + image search
â”œâ”€â”€ classificador_mfcc.py          # MFCC-based audio classification
â”œâ”€â”€ menu_principal.py              # CLI menu interface
â”œâ”€â”€ model_mobilenet_finetuned.h5   # Spectrogram model (MobileNetV2 head)
â”œâ”€â”€ model_mfcc.h5                  # MFCC CNN model
â”œâ”€â”€ train_audio/                   # Training audio files organized by species
â””â”€â”€ spectrograms/                  # Generated spectrogram images for train/test
\`\`\`

---

## âš™ï¸ Core Features

### 1. Spectrogram Classification  
- Converts a 5 s \`.ogg\` clip into a 128Ã—128 Mel-spectrogram image  
- Classifies with a fine-tuned MobileNetV2 head  

### 2. MFCC Classification  
- Extracts 13 MFCC coefficients, fixed to a 13Ã—216 shape  
- Classifies with a small 2-layer Conv2D network  

### 3. Text Description (Gemini)  
- Sends the predicted species name to Google Gemini  
- Prints a concise, informative description  

### 4. Real-World Image Search  
- Opens your browser to a Google Images query for the predicted species  

---

## â–¶ï¸ Getting Started

1. **Clone the repo** and \`cd ecoauralia/\`  
2. **Install dependencies**  
   \`\`\`bash
   pip install tensorflow librosa matplotlib numpy google-generativeai
   \`\`\`  
3. **Run the CLI menu**  
   \`\`\`bash
   python menu_principal.py
   \`\`\`  
4. **Follow the prompts** to choose classification, description, image search or the full pipeline.

---

## ðŸ§ª Example Session

\`\`\`
ðŸŒ¿ ECOAURALIA ðŸŒ¿
1 â€“ Classify by Spectrogram (.ogg)
2 â€“ Classify by MFCC       (.ogg)
3 â€“ Get Text Description
4 â€“ Search Real Images
5 â€“ Full Pipeline
6 â€“ Exit
ðŸ‘‰ Choose an option: 1
\`\`\`

---

## ðŸ’¡ Notes & Considerations

- Training data is organized by species folders under \`train_audio/\`.  
- Spectrogram model fine-tuned with data augmentation and class-weighting to handle imbalance.  
- MFCC model trained for 40 epochs with sparse categorical cross-entropy and balanced classes.  
- Image synthesis via Diffusers was removed to keep the project lightweight and fully local.  
- Audio quality and class balance directly impact classification accuracy.  
- Gathering clean, diverse animal audio samples can be challenging.

---

> Developed as the first evaluative assignment in the IA 1 course.
